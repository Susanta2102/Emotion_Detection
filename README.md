<div align="center">
  <br />
    <a href="" target="_blank">
      <img src="https://github.com/thebugged/emotion-detection/assets/74977495/340fcd9b-50b7-4581-b9bc-2e2a1239aae4" alt="Banner">
    </a>
  <br />

  <div>
    <img src="https://img.shields.io/badge/-Python-black?style=for-the-badge&logoColor=white&logo=python&color=3776AB" alt="python" />
    <img src="https://img.shields.io/badge/-TensorFlow-black?style=for-the-badge&logoColor=white&logo=tensorflow&color=FF6F00" alt="tensorflow" />
    <img src="https://img.shields.io/badge/-scikit_learn-black?style=for-the-badge&logoColor=white&logo=scikitlearn&color=F7931E" alt="scikit-learn" />
    <img src="https://img.shields.io/badge/-Streamlit-black?style=for-the-badge&logoColor=white&logo=streamlit&color=FF4B4B" alt="streamlit" />
</div>


  <h3 align="center">Emotion Detection</h3>

   <div align="center">
     Either Neutral, Calm, Happy, Sad, Anger, Fear, Disgust, or Surprise, the app detects the emotion from either uploads of an audio, image, video or in real-time processing. 
    </div>
</div>
<br/>

**Datasets** üóÉÔ∏è
- [FER-2013](https://www.kaggle.com/datasets/msambare/fer2013)
- [RAVDESS Emotional speech audio](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) 
- [Toronto emotional speech set (TESS)](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)


## Setup & Installation
**Prerequisites**

Ensure the following are installed
- [Git](https://git-scm.com/)
- [Python](https://www.python.org/downloads/)
- [Jupter Notebook](https://jupyter.org/install) (or install the Jupyter extension on Visual Studio Code).
  
To set up this project locally, follow these steps:

1. Clone the repository:
```shell
git clone https://github.com/thebugged/emotion-detection.git
```

2. Change into the project directory: 
```shell
cd emotion-detection
```

3. Install the required dependencies: 
```shell
pip install -r requirements.txt
```
<br/>

## Running the application
1. Run the command: 
```shell
streamlit run main.py
```
2. Alternatively, you can run the `face.ipynb` and `speech.ipynb` notebooks to get their respective models then run the command in 1.

The application will be available in your browser at http://localhost:8501.


